{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up OpenAI client\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"fill in API key\"\n",
    "\n",
    "# Define model configurations\n",
    "base_model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "# Load datasets directly from parquet files\n",
    "# Assuming these are the paths to your parquet files - adjust as needed\n",
    "sept_news_text_df = pd.read_csv(\"datasets/latest_news/latest_news_memorization.csv\")\n",
    "sept_news_text_rephrased_df = pd.read_csv(\n",
    "    \"datasets/latest_news/latest_news_rephrased.csv\"\n",
    ")\n",
    "sept_news_text_date_changed_df = pd.read_csv(\n",
    "    \"datasets/latest_news/latest_news_date_changed.csv\"\n",
    ")\n",
    "\n",
    "### Subset datasets where used_in_analysis is True\n",
    "sept_news_text_df = sept_news_text_df[sept_news_text_df[\"used_in_analysis\"] == True]\n",
    "sept_news_text_rephrased_df = sept_news_text_rephrased_df[\n",
    "    sept_news_text_rephrased_df[\"used_in_analysis\"] == True\n",
    "]\n",
    "sept_news_text_date_changed_df = sept_news_text_date_changed_df[\n",
    "    sept_news_text_date_changed_df[\"used_in_analysis\"] == True\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating original dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [00:23<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating rephrased dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating date_changed dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def evaluate_dataset(df, model_name, temperature=0, max_tokens=100):\n",
    "    \"\"\"\n",
    "    Evaluate a dataset using OpenAI API\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating\"):\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"user\", \"content\": row[\"prompt\"]})\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                seed=42,\n",
    "            )\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call: {e}\")\n",
    "            answer = \"<error>\"\n",
    "\n",
    "        result = {\n",
    "            \"prompt\": row[\"prompt\"],\n",
    "            \"raw_response\": answer,\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"model\": model_name,\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Evaluate each dataset\n",
    "datasets = {\n",
    "    \"original\": sept_news_text_df,\n",
    "    \"rephrased\": sept_news_text_rephrased_df,\n",
    "    \"date_changed\": sept_news_text_date_changed_df,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nEvaluating {name} dataset...\")\n",
    "    results[name] = evaluate_dataset(\n",
    "        df=df, model_name=base_model_name, temperature=0, max_tokens=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each dataset\n",
    "accuracy_results = []\n",
    "\n",
    "for dataset_name, df in results.items():\n",
    "    # Calculate exact match accuracy\n",
    "    accuracy = (\n",
    "        df[\"raw_response\"].astype(str).str.lower()\n",
    "        == df[\"answer\"].astype(str).str.lower()\n",
    "    ).mean()\n",
    "\n",
    "    accuracy_results.append(\n",
    "        {\"model\": base_model_name, \"dataset\": dataset_name, \"accuracy\": accuracy}\n",
    "    )\n",
    "\n",
    "# Create accuracy DataFrame\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
